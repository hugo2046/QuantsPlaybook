"""
Author: Hugo
Date: 2025-10-28 13:41:02
LastEditors: shen.lan123@gmail.com
LastEditTime: 2025-10-29 15:09:45
Description:
é¢†å…ˆ-æ»åç½‘ç»œæ„å»ºæ¨¡å—

æœ¬æ¨¡å—æä¾›ä»é‡‘èæ•°æ®æ„å»ºé¢†å…ˆ-æ»åç½‘ç»œçš„åŠŸèƒ½ï¼Œé‡ç‚¹å…³æ³¨éš”å¤œä¸æ—¥é—´æ”¶ç›Šå…³ç³»ã€‚

åŸºäº: "A tug of war across the market: overnight-vs-daytime lead-lag networks
and clustering-based portfolio strategies" (ç¬¬3.2èŠ‚)

æ ¸å¿ƒåŠŸèƒ½ï¼š
- æ”¶ç›Šç‡åˆ†è§£ï¼šå°†æ—¥æ”¶ç›Šç‡åˆ†è§£ä¸ºéš”å¤œå’Œæ—¥é—´æˆåˆ†
- ç½‘ç»œæ„å»ºï¼šæ„å»ºä¸‰ç§ç±»å‹çš„é¢†å…ˆ-æ»åç½‘ç»œ
- ç›¸å…³æ€§è®¡ç®—ï¼šæ”¯æŒPearsonå’ŒSpearmanç›¸å…³æ€§
"""

from typing import List, Tuple

import numpy as np
import pandas as pd
from pandas.core.algorithms import rank as pandas_rank
from qlib_data_provider import QlibDataProvider
from scipy.stats import rankdata

from utils import sliding_window

# æ™ºèƒ½å¹¶è¡Œé…ç½®ç±»
class ParallelConfig:
    """å¹¶è¡Œè®¡ç®—é…ç½®ç±»"""
    def __init__(self):
        self.max_memory_usage_ratio = 0.7  # æœ€å¤§å†…å­˜ä½¿ç”¨æ¯”ä¾‹
        self.min_chunk_size = 1
        self.max_chunk_size = 100
        self.enable_auto_adjustment = True
        self.fallback_to_single_process = True
        self.min_n_jobs = 1
        self.max_n_jobs = None  # Noneè¡¨ç¤ºä¸é™åˆ¶


def _get_system_resources():
    """
    è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯

    Returns
    -------
    dict
        åŒ…å«CPUæ ¸å¿ƒæ•°ã€å¯ç”¨å†…å­˜ç­‰ä¿¡æ¯
    """
    try:
        import psutil
        return {
            'cpu_cores': psutil.cpu_count(),
            'available_memory_gb': psutil.virtual_memory().available / (1024**3),
            'total_memory_gb': psutil.virtual_memory().total / (1024**3),
        }
    except ImportError:
        # å¦‚æœpsutilä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€ä¼°è®¡
        import multiprocessing
        return {
            'cpu_cores': multiprocessing.cpu_count(),
            'available_memory_gb': 4.0,  # ä¿å®ˆä¼°è®¡4GB
            'total_memory_gb': 8.0,   # ä¿å®ˆä¼°è®¡8GB
        }


def _auto_adjust_n_jobs(requested_n_jobs: int, data_shape: Tuple[int, int],
                       config: ParallelConfig = None) -> int:
    """
    è‡ªåŠ¨è°ƒæ•´n_jobsä»¥é€‚åº”ç³»ç»Ÿèµ„æº

    Parameters
    ----------
    requested_n_jobs : int
        ç”¨æˆ·è¯·æ±‚çš„n_jobs
    data_shape : Tuple[int, int]
        æ•°æ®å½¢çŠ¶
    config : ParallelConfig, optional
        å¹¶è¡Œé…ç½®

    Returns
    -------
    int
        è°ƒæ•´åçš„n_jobs
    """
    if config is None:
        config = ParallelConfig()

    # è·å–ç³»ç»Ÿèµ„æº
    resources = _get_system_resources()
    cpu_cores = resources['cpu_cores']
    available_memory_gb = resources['available_memory_gb']

    # å¦‚æœç¦ç”¨è‡ªåŠ¨è°ƒæ•´ï¼Œç›´æ¥è¿”å›
    if not config.enable_auto_adjustment:
        return min(requested_n_jobs, cpu_cores if config.max_n_jobs is None else config.max_n_jobs)

    # åŸºäºCPUæ ¸å¿ƒæ•°çš„é™åˆ¶
    max_by_cpu = cpu_cores if config.max_n_jobs is None else min(cpu_cores, config.max_n_jobs)

    # åŸºäºå†…å­˜çš„é™åˆ¶ï¼ˆä½¿ç”¨ç®€åŒ–çš„å†…å­˜ä¼°ç®—ï¼‰
    T, N = data_shape
    base_memory_gb = (T * N * 8) / (1024**3)  # åŸºç¡€æ•°æ®å†…å­˜
    memory_per_process = base_memory_gb * 2  # ä¼°ç®—åŒ…æ‹¬ä¸´æ—¶è®¡ç®—å†…å­˜
    max_by_memory = int(available_memory_gb * config.max_memory_usage_ratio / memory_per_process)

    # é€‰æ‹©æœ€å°å€¼
    recommended_n_jobs = min(requested_n_jobs, max_by_cpu, max_by_memory)

    # ç¡®ä¿ä¸å°äºæœ€å°å€¼
    final_n_jobs = max(config.min_n_jobs, recommended_n_jobs)

    # å¦‚æœè°ƒæ•´äº†n_jobsï¼Œç»™å‡ºè­¦å‘Š
    if final_n_jobs != requested_n_jobs:
        print(f"âš ï¸  èµ„æºé™åˆ¶ï¼šå°†n_jobsä»{requested_n_jobs}è°ƒæ•´åˆ°{final_n_jobs}")
        print(f"   CPUé™åˆ¶: {max_by_cpu}æ ¸å¿ƒ")
        print(f"   å†…å­˜é™åˆ¶: {max_by_memory}è¿›ç¨‹")
        print(f"   å¯ç”¨å†…å­˜: {available_memory_gb:.1f}GB")

    return final_n_jobs




def _compute_pearson_matrix(
    lead_returns: np.ndarray, lag_returns: np.ndarray
) -> np.ndarray:
    """
    é«˜æ•ˆè®¡ç®—é¢†å…ˆ-æ»åç›¸å…³æ€§çŸ©é˜µ (å‘é‡åŒ–å®ç°)ã€‚

    Parameters
    ----------
    lead_returns : np.ndarray
        é¢†å…ˆä¿¡å·çš„æ”¶ç›Šç‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (T, N)ï¼ŒTä¸ºæ—¶é—´æ­¥ï¼ŒNä¸ºèµ„äº§æ•°ã€‚
    lag_returns : np.ndarray
        æ»åä¿¡å·çš„æ”¶ç›Šç‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (T, N)ã€‚

    Returns
    -------
    np.ndarray
        ç›¸å…³æ€§çŸ©é˜µ M (N, N)ï¼Œå…¶ä¸­ M[i, j] = Corr(lead_i, lag_j)ã€‚
    """
    assert (
        lead_returns.shape == lag_returns.shape
    ), f"å½¢çŠ¶ä¸åŒ¹é…: {lead_returns.shape} vs {lag_returns.shape}"

    T, N = lead_returns.shape
    if T <= 1:
        return np.zeros((N, N))

    # æ ‡å‡†åŒ– (ä½¿ç”¨æ ·æœ¬æ ‡å‡†å·®, ddof=1)
    lead_mean = np.mean(lead_returns, axis=0, keepdims=True)
    lead_std = np.std(lead_returns, axis=0, ddof=1, keepdims=True) + 1e-8
    lead_normalized = (lead_returns - lead_mean) / lead_std

    lag_mean = np.mean(lag_returns, axis=0, keepdims=True)
    lag_std = np.std(lag_returns, axis=0, ddof=1, keepdims=True) + 1e-8
    lag_normalized = (lag_returns - lag_mean) / lag_std

    # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
    # æ³¨æ„ï¼šå› ä¸ºä½¿ç”¨äº†æ ·æœ¬æ ‡å‡†å·®(ddof=1)ï¼Œè¿™é‡Œçš„åˆ†æ¯æ˜¯ (T-1)
    M = (lead_normalized.T @ lag_normalized) / (T - 1)

    # å¤„ç†å› æµ®ç‚¹æ•°è®¡ç®—äº§ç”Ÿçš„å¾®å°è¯¯å·®ï¼Œç¡®ä¿ç›¸å…³ç³»æ•°åœ¨ [-1, 1] èŒƒå›´å†…
    M = np.clip(M, -1, 1)

    return M

def _compute_spearman_matrix(
    lead_returns: np.ndarray, lag_returns: np.ndarray
) -> np.ndarray:
    """
    é«˜æ•ˆè®¡ç®—é¢†å…ˆ-æ»åæ–¯çš®å°”æ›¼ç›¸å…³æ€§çŸ©é˜µï¼ˆPandasæ ¸å¿ƒç®—æ³•ä¼˜åŒ–ç‰ˆï¼‰ã€‚

    ç›´æ¥ä½¿ç”¨pandas.core.algorithms.rankï¼Œé¿å…DataFrameè½¬æ¢å¼€é”€ã€‚
    æ¯”scipy.stats.rankdataå¿«10-100å€ã€‚

    Parameters
    ----------
    lead_returns : np.ndarray
        é¢†å…ˆä¿¡å·çš„æ”¶ç›Šç‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (T, N)ï¼ŒTä¸ºæ—¶é—´æ­¥ï¼ŒNä¸ºèµ„äº§æ•°ã€‚
    lag_returns : np.ndarray
        æ»åä¿¡å·çš„æ”¶ç›Šç‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (T, N)ã€‚

    Returns
    -------
    np.ndarray
        æ–¯çš®å°”æ›¼ç›¸å…³æ€§çŸ©é˜µ M (N, N)ï¼Œå…¶ä¸­ M[i, j] = SpearmanCorr(lead_i, lag_j)ã€‚
    """
    assert (
        lead_returns.shape == lag_returns.shape
    ), f"å½¢çŠ¶ä¸åŒ¹é…: {lead_returns.shape} vs {lag_returns.shape}"

    T, N = lead_returns.shape
    if T <= 1:
        return np.zeros((N, N))

    try:

        # ä½¿ç”¨pandasçš„rankç®—æ³•ç›´æ¥å¤„ç†numpyæ•°ç»„
        lead_ranks = pandas_rank(
            lead_returns,
            axis=0,              # æ²¿æ—¶é—´è½´æ’å
            method='average',    # å¤„ç†å¹¶åˆ—å€¼
            na_option='keep',    # ä¿æŒNaNå€¼
            ascending=True,      # å‡åºæ’å
            pct=False           # è¿”å›ç§©æ¬¡è€Œéç™¾åˆ†æ¯”
        )

        lag_ranks = pandas_rank(
            lag_returns,
            axis=0,
            method='average',
            na_option='keep',
            ascending=True,
            pct=False
        )

    except (ImportError, AttributeError) as e:
        # å¦‚æœpandaså†…éƒ¨APIä¸å¯ç”¨ï¼Œå›é€€åˆ°scipy
        print(f"è­¦å‘Šï¼špandasæ ¸å¿ƒç®—æ³•ä¸å¯ç”¨ï¼Œä½¿ç”¨scipy rankdata: {e}")
        lead_ranks = np.apply_along_axis(rankdata, 0, lead_returns)
        lag_ranks = np.apply_along_axis(rankdata, 0, lag_returns)

    # å¯¹ç§©æ¬¡æ•°æ®è®¡ç®—çš®å°”é€Šç›¸å…³æ€§
    return _compute_pearson_matrix(lead_ranks, lag_ranks)


def compute_rolling_lead_lag(
    df1: pd.DataFrame,
    df2: pd.DataFrame,
    window: int,
    align_index: bool = False,
    method: str = "pearson",
    n_jobs: int = -1,
    parallel_config: ParallelConfig = None,
) -> np.ndarray:
    """
    åœ¨æ»šåŠ¨çª—å£ä¸Šï¼Œè®¡ç®—ä¸¤ä¸ªDataFrameæ¯åˆ—ä¹‹é—´çš„ç›¸å…³æ€§ï¼ˆå†…å­˜å®‰å…¨ç‰ˆï¼‰ã€‚

    Parameters
    ----------
    df1 : pd.DataFrame
        ç¬¬ä¸€ä¸ªDataFrame (ä¾‹å¦‚, éš”å¤œæ”¶ç›Šç‡)ã€‚
    df2 : pd.DataFrame
        ç¬¬äºŒä¸ªDataFrame (ä¾‹å¦‚, æ—¥é—´æ”¶ç›Šç‡)ã€‚
    window : int
        æ»šåŠ¨çª—å£çš„å¤§å°ã€‚
    align_index : bool, optional
        æ˜¯å¦åœ¨è®¡ç®—å‰å¯¹é½ä¸¤ä¸ªDataFrameçš„ç´¢å¼•å’Œåˆ—, by default Falseã€‚
    method : str, optional
        ç›¸å…³æ€§è®¡ç®—æ–¹æ³• ('pearson' æˆ– 'spearman'), by default "pearson"ã€‚
    n_jobs : int, optional
        å¹¶è¡Œè¿è¡Œçš„ä½œä¸šæ•°, by default -1ï¼ˆå°†æ ¹æ®ç³»ç»Ÿèµ„æºè‡ªåŠ¨è°ƒæ•´ï¼‰ã€‚
    parallel_config : ParallelConfig, optional
        å¹¶è¡Œè®¡ç®—é…ç½®ï¼Œby default Noneï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰ã€‚

    Returns
    -------
    np.ndarray
        ä¸€ä¸ªä¸‰ç»´æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (D, N, N)ï¼Œ
        Dä¸ºæ»šåŠ¨çª—å£æ•°ï¼ŒNä¸ºèµ„äº§æ•°ã€‚ä»£è¡¨æ¯ä¸ªæ—¶é—´ç‚¹çš„ç›¸å…³æ€§çŸ©é˜µã€‚
    """
    if align_index:
        df1, df2 = df1.align(df2)

    # è·å–æ•°æ®å½¢çŠ¶å’Œçª—å£æ•°
    T, N = df1.shape
    total_windows = T - window + 1

    if total_windows <= 0:
        raise ValueError(f"çª—å£å¤§å°({window})å¤§äºæ•°æ®é•¿åº¦({T})")

    # ğŸš¨ å†…å­˜å®‰å…¨æ£€æŸ¥
    print(f"ğŸ“Š æ•°æ®æ£€æŸ¥: {T}å¤© Ã— {N}åªè‚¡ç¥¨, çª—å£{window}å¤©, æ€»è®¡{total_windows}ä¸ªçª—å£")

    # è¯„ä¼°å†…å­˜éœ€æ±‚
    memory_safe, recommended_n_jobs = _assess_memory_safety(df1, window, method, n_jobs, parallel_config)

    # é€‰æ‹©è®¡ç®—æ–¹æ³•
    if method.lower() == "pearson":
        compute_func = _compute_pearson_matrix
    elif method.lower() == "spearman":
        compute_func = _compute_spearman_matrix
    else:
        raise ValueError(f"æœªçŸ¥çš„ç›¸å…³æ€§è®¡ç®—æ–¹æ³•: {method}")

    if memory_safe:
        print(f"âœ… å†…å­˜å®‰å…¨ï¼Œä½¿ç”¨{n_jobs}ä¸ªè¿›ç¨‹å¹¶è¡Œè®¡ç®—")
        return _safe_parallel_compute(df1, df2, window, compute_func, n_jobs, parallel_config)
    else:
        print(f"âš ï¸  å†…å­˜ä¸è¶³ï¼Œä½¿ç”¨æµå¼å•è¿›ç¨‹è®¡ç®—")
        return _streaming_compute(df1, df2, window, compute_func)


def _assess_memory_safety(df1: pd.DataFrame, window: int,
                          method: str, n_jobs: int, config: ParallelConfig = None) -> Tuple[bool, int]:
    """
    è¯„ä¼°å†…å­˜å®‰å…¨æ€§ï¼Œé¿å…å°†ç”Ÿæˆå™¨è½¬æ¢ä¸ºåˆ—è¡¨

    Returns
    -------
    Tuple[bool, int]
        (æ˜¯å¦å®‰å…¨, æ¨èçš„n_jobs)
    """
    if config is None:
        config = ParallelConfig()
        # ä½¿ç”¨æ›´ä¿å®ˆçš„é»˜è®¤è®¾ç½®
        config.max_memory_usage_ratio = 0.2  # åªä½¿ç”¨20%å†…å­˜
        config.fallback_to_single_process = True

    # è·å–ç³»ç»Ÿèµ„æº
    resources = _get_system_resources()
    available_memory_gb = resources['available_memory_gb']

    # è®¡ç®—å†…å­˜éœ€æ±‚ï¼ˆæ›´ä¿å®ˆçš„ä¼°è®¡ï¼‰
    T, N = df1.shape

    # 1. åŸå§‹æ•°æ®å†…å­˜
    base_data_gb = (T * N * 8) / (1024**3)

    # 2. æ–¹æ³•ç‰¹å®šå†…å­˜
    if method == "spearman":
        # Spearmanéœ€è¦æ’åæ•°æ®
        method_multiplier = 2.5
    else:
        method_multiplier = 1.5

    # 3. å¹¶è¡Œå†…å­˜ä¹˜æ•°
    if n_jobs > 1:
        parallel_multiplier = min(n_jobs, resources['cpu_cores'])
    else:
        parallel_multiplier = 1

    # æ€»å†…å­˜éœ€æ±‚
    total_memory_gb = base_data_gb * parallel_multiplier * method_multiplier

    # ä¿å®ˆçš„å®‰å…¨ç³»æ•°
    safety_factor = 3.0  # éå¸¸ä¿å®ˆçš„å®‰å…¨ç³»æ•°
    estimated_memory_gb = total_memory_gb * safety_factor

    memory_ratio = estimated_memory_gb / available_memory_gb
    memory_safe = memory_ratio < config.max_memory_usage_ratio

    # è®¡ç®—æ¨èçš„n_jobs
    max_safe_n_jobs = int(available_memory_gb * config.max_memory_usage_ratio /
                         (base_data_gb * method_multiplier * safety_factor))
    recommended_n_jobs = max(config.min_n_jobs, min(n_jobs, max_safe_n_jobs))

    print(f"   å†…å­˜ä¼°ç®—: {estimated_memory_gb:.2f}GB (å®‰å…¨æ¯”ä¾‹: {memory_ratio:.1%})")
    print(f"   æ¨èn_jobs: {recommended_n_jobs}")

    return memory_safe, recommended_n_jobs


def _safe_parallel_compute(df1: pd.DataFrame, df2: pd.DataFrame, window: int,
                          compute_func: callable, n_jobs: int, config: ParallelConfig) -> np.ndarray:
    """
    å®‰å…¨çš„å¹¶è¡Œè®¡ç®—å®ç°ï¼ˆé¿å…å†…å­˜çˆ†ç‚¸ï¼‰
    """
    features_arrs = np.stack([df1.values, df2.values], axis=1)
    roll_arrs = sliding_window(features_arrs, window)

    # è®¡ç®—æ€»çª—å£æ•°ï¼ˆä¸è½¬æ¢ä¸ºåˆ—è¡¨ï¼‰
    T = df1.shape[0]
    total_windows = T - window + 1

    # æ™ºèƒ½è°ƒæ•´n_jobs
    _, adjusted_n_jobs = _assess_memory_safety(df1, window, "spearman", n_jobs, config)

    # ä¿å®ˆçš„chunkå¤§å°
    chunk_size = max(1, min(10, total_windows // (adjusted_n_jobs * 4)))

    print(f"   Chunkå¤§å°: {chunk_size}, æ€»chunks: {(total_windows + chunk_size - 1) // chunk_size}")

    # æµå¼å¤„ç†ï¼Œé¿å…å†…å­˜çˆ†ç‚¸
    results = []
    chunk = []

    for i, window_data in enumerate(roll_arrs):
        chunk.append(window_data)

        if len(chunk) >= chunk_size:
            # å¤„ç†å½“å‰chunk
            chunk_results = [compute_func(data[:, 0, :], data[:, 1, :]) for data in chunk]
            results.extend(chunk_results)
            chunk = []  # ç«‹å³æ¸…ç©ºchunkï¼Œé‡Šæ”¾å†…å­˜

        if (i + 1) % 100 == 0:
            print(f"   è¿›åº¦: {i+1}/{total_windows}")

    # å¤„ç†å‰©ä½™æ•°æ®
    if chunk:
        chunk_results = [compute_func(data[:, 0, :], data[:, 1, :]) for data in chunk]
        results.extend(chunk_results)

    return np.array(results)


def _streaming_compute(df1: pd.DataFrame, df2: pd.DataFrame, window: int,
                       compute_func: callable) -> np.ndarray:
    """
    æµå¼è®¡ç®—å®ç°ï¼ˆæœ€å®‰å…¨ï¼Œå•è¿›ç¨‹ï¼Œé€ä¸ªå¤„ç†ï¼‰
    """
    features_arrs = np.stack([df1.values, df2.values], axis=1)
    roll_arrs = sliding_window(features_arrs, window)

    T = df1.shape[0]
    total_windows = T - window + 1

    print(f"   æµå¼å¤„ç†æ¨¡å¼ï¼šé€ä¸ªè®¡ç®—{total_windows}ä¸ªçª—å£")

    results = []
    for i, window_data in enumerate(roll_arrs):
        if i % 100 == 0:
            print(f"   è¿›åº¦: {i+1}/{total_windows}")

        result = compute_func(window_data[:, 0, :], window_data[:, 1, :])
        results.append(result)

    return np.array(results)


class LeadLagNetworkBuilder:
    """
    ä»é‡‘èä»·æ ¼æ•°æ®æ„å»ºé¢†å…ˆ-æ»åç½‘ç»œçš„ç±»ã€‚

    è¯¥ç±»å°è£…äº†æ„å»ºå¤šç§ç±»å‹çš„é¢†å…ˆ-æ»åçŸ©é˜µçš„é€»è¾‘ï¼Œå¦‚è®ºæ–‡3.2èŠ‚æ‰€è¿°ï¼š
    1. éš”å¤œ-é¢†å…ˆ-æ—¥é—´ï¼šM[i,j] = Corr(overnight_returns_i, daytime_returns_j)
    2. æ—¥é—´-é¢†å…ˆ-éš”å¤œï¼šM[i,j] = Corr(daytime_returns_i[t-1], overnight_returns_j[t])

    æ”¯æŒä¸¤ç§ç›¸å…³æ€§è®¡ç®—æ–¹æ³•ï¼š
    - Pearsonï¼šçº¿æ€§ç›¸å…³æ€§ï¼Œè®¡ç®—æ•ˆç‡é«˜ï¼Œé€‚ç”¨äºçº¿æ€§å…³ç³»
    - Spearmanï¼šå•è°ƒç›¸å…³æ€§ï¼Œå¯¹å¼‚å¸¸å€¼ç¨³å¥ï¼Œé€‚ç”¨äºéçº¿æ€§å…³ç³»

    ä½¿ç”¨æµç¨‹:
    1. åˆå§‹åŒ–ç±»ï¼Œæä¾›æ•°æ®æºã€å›çœ‹çª—å£å’Œç›¸å…³æ€§æ–¹æ³•ã€‚
    2. è°ƒç”¨ `build_network` æ–¹æ³•æ„å»ºç‰¹å®šç±»å‹çš„ç½‘ç»œã€‚
    """

    def __init__(
        self,
        qlib_provider: QlibDataProvider,
        lookback_window: int = 60,
        correlation_method: str = "pearson",
        n_jobs: int = -1,
        parallel_config: ParallelConfig = None,
    ):
        """
        åˆå§‹åŒ–é¢†å…ˆ-æ»åç½‘ç»œæ„å»ºå™¨ã€‚

        Parameters
        ----------
        qlib_provider : QlibDataProvider
            æä¾›æ”¶ç›Šç‡æ•°æ®çš„Qlibæ•°æ®æä¾›è€…å®ä¾‹ã€‚
        lookback_window : int, optional
            ç”¨äºè®¡ç®—ç›¸å…³æ€§çš„æ»šåŠ¨çª—å£å¤©æ•°, by default 60ã€‚
        correlation_method : str, optional
            ç›¸å…³æ€§è®¡ç®—æ–¹æ³•, å¯é€‰ 'pearson' æˆ– 'spearman', by default "pearson"ã€‚
            - 'pearson': çš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œé€‚ç”¨äºçº¿æ€§å…³ç³»
            - 'spearman': æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•°ï¼Œå¯¹å¼‚å¸¸å€¼ç¨³å¥
        n_jobs : int, optional
            å¹¶è¡Œè®¡ç®—çš„ä½œä¸šæ•°, by default -1ã€‚
            - -1: ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ
            - 1: ä¸ä½¿ç”¨å¹¶è¡Œè®¡ç®—ï¼ˆå•è¿›ç¨‹ï¼‰
            - >1: ä½¿ç”¨æŒ‡å®šæ•°é‡çš„CPUæ ¸å¿ƒ
        parallel_config : ParallelConfig, optional
            å¹¶è¡Œè®¡ç®—é…ç½®ï¼Œby default Noneï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰ã€‚
        """
        self._qlib_provider = qlib_provider
        self._lookback_window = lookback_window
        self._correlation_method = self._validate_correlation_method(correlation_method)
        self._parallel_config = parallel_config if parallel_config is not None else ParallelConfig()

        # åˆå§‹åŒ–æ—¶å…ˆä¸è°ƒæ•´n_jobsï¼Œåœ¨build_networkæ—¶æ ¹æ®æ•°æ®åŠ¨æ€è°ƒæ•´
        self._requested_n_jobs = self._validate_n_jobs(n_jobs)
        self._n_jobs = self._requested_n_jobs

    def _validate_correlation_method(self, method: str) -> str:
        """
        éªŒè¯ç›¸å…³æ€§è®¡ç®—æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

        Parameters
        ----------
        method : str
            å¾…éªŒè¯çš„ç›¸å…³æ€§æ–¹æ³•åç§°

        Returns
        -------
        str
            éªŒè¯åçš„æ–¹æ³•åç§°ï¼ˆå°å†™ï¼‰

        Raises
        ------
        ValueError
            å½“æ–¹æ³•åç§°ä¸æ”¯æŒæ—¶
        """
        supported_methods = ['pearson', 'spearman']
        method_lower = method.lower()

        if method_lower not in supported_methods:
            raise ValueError(
                f"ä¸æ”¯æŒçš„ç›¸å…³æ€§æ–¹æ³•: {method}. "
                f"æ”¯æŒçš„æ–¹æ³•: {supported_methods}"
            )

        return method_lower

    def _validate_n_jobs(self, n_jobs: int) -> int:
        """
        éªŒè¯å¹¶è¡Œä½œä¸šæ•°å‚æ•°çš„æœ‰æ•ˆæ€§ã€‚

        Parameters
        ----------
        n_jobs : int
            å¾…éªŒè¯çš„å¹¶è¡Œä½œä¸šæ•°

        Returns
        -------
        int
            éªŒè¯åçš„ä½œä¸šæ•°

        Raises
        ------
        ValueError
            å½“ä½œä¸šæ•°ä¸æ˜¯æ­£æ•´æ•°æ—¶
        """
        if not isinstance(n_jobs, int) or n_jobs == 0:
            raise ValueError(
                f"n_jobså¿…é¡»æ˜¯æ•´æ•°ä¸”ä¸ä¸º0ï¼Œå½“å‰å€¼: {n_jobs}"
            )
        return n_jobs

    @property
    def correlation_method(self) -> str:
        """
        è·å–å½“å‰ä½¿ç”¨çš„ç›¸å…³æ€§è®¡ç®—æ–¹æ³•ã€‚

        Returns
        -------
        str
            å½“å‰ç›¸å…³æ€§æ–¹æ³• ('pearson' æˆ– 'spearman')
        """
        return self._correlation_method

    @property
    def n_jobs(self) -> int:
        """
        è·å–å½“å‰ä½¿ç”¨çš„å¹¶è¡Œä½œä¸šæ•°ã€‚

        Returns
        -------
        int
            å½“å‰çš„å¹¶è¡Œä½œä¸šæ•°
        """
        return self._n_jobs

    def set_correlation_method(self, method: str) -> None:
        """
        è®¾ç½®ç›¸å…³æ€§è®¡ç®—æ–¹æ³•ã€‚

        Parameters
        ----------
        method : str
            æ–°çš„ç›¸å…³æ€§è®¡ç®—æ–¹æ³• ('pearson' æˆ– 'spearman')

        Raises
        ------
        ValueError
            å½“æ–¹æ³•åç§°ä¸æ”¯æŒæ—¶
        """
        self._correlation_method = self._validate_correlation_method(method)

    def set_n_jobs(self, n_jobs: int) -> None:
        """
        è®¾ç½®å¹¶è¡Œä½œä¸šæ•°ã€‚

        Parameters
        ----------
        n_jobs : int
            æ–°çš„å¹¶è¡Œä½œä¸šæ•°
            - -1: ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„CPUæ ¸å¿ƒ
            - 1: ä¸ä½¿ç”¨å¹¶è¡Œè®¡ç®—ï¼ˆå•è¿›ç¨‹ï¼‰
            - >1: ä½¿ç”¨æŒ‡å®šæ•°é‡çš„CPUæ ¸å¿ƒ

        Raises
        ------
        ValueError
            å½“ä½œä¸šæ•°ä¸æ˜¯æ­£æ•´æ•°æ—¶
        """
        self._requested_n_jobs = self._validate_n_jobs(n_jobs)
        self._n_jobs = self._requested_n_jobs

    def set_parallel_config(self, config: ParallelConfig) -> None:
        """
        è®¾ç½®å¹¶è¡Œè®¡ç®—é…ç½®ã€‚

        Parameters
        ----------
        config : ParallelConfig
            æ–°çš„å¹¶è¡Œé…ç½®
        """
        self._parallel_config = config

    def get_parallel_config(self) -> ParallelConfig:
        """
        è·å–å½“å‰çš„å¹¶è¡Œé…ç½®ã€‚

        Returns
        -------
        ParallelConfig
            å½“å‰çš„å¹¶è¡Œé…ç½®
        """
        return self._parallel_config

    def check_memory_requirements(self, data_shape: Tuple[int, int], method: str = None) -> dict:
        """
        æ£€æŸ¥å†…å­˜éœ€æ±‚å¹¶ç»™å‡ºå»ºè®®ã€‚

        Parameters
        ----------
        data_shape : Tuple[int, int]
            æ•°æ®å½¢çŠ¶ (T, N)
        method : str, optional
            è®¡ç®—æ–¹æ³•ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰è®¾ç½®çš„æ–¹æ³•

        Returns
        -------
        dict
            åŒ…å«å†…å­˜åˆ†æç»“æœçš„å­—å…¸
        """
        if method is None:
            method = self._correlation_method

        # è·å–ç³»ç»Ÿèµ„æº
        resources = _get_system_resources()

        # ä¼°ç®—å†…å­˜éœ€æ±‚ï¼ˆä½¿ç”¨ç®€åŒ–æ–¹æ³•ï¼‰
        T, N = data_shape
        base_memory_gb = (T * N * 8) / (1024**3)
        if method == "spearman":
            method_multiplier = 2.5  # Spearmanéœ€è¦é¢å¤–å†…å­˜
        else:
            method_multiplier = 1.5
        estimated_memory = base_memory_gb * method_multiplier * min(self._requested_n_jobs, 4)

        # å»ºè®®çš„n_jobs
        recommended_n_jobs = _auto_adjust_n_jobs(self._requested_n_jobs, data_shape, self._parallel_config)

        analysis = {
            'data_shape': data_shape,
            'method': method,
            'requested_n_jobs': self._requested_n_jobs,
            'recommended_n_jobs': recommended_n_jobs,
            'estimated_memory_gb': estimated_memory,
            'available_memory_gb': resources['available_memory_gb'],
            'cpu_cores': resources['cpu_cores'],
            'memory_usage_ratio': estimated_memory / resources['available_memory_gb'],
            'needs_adjustment': recommended_n_jobs != self._requested_n_jobs,
            'warning_level': 'normal'
        }

        # ç¡®å®šè­¦å‘Šçº§åˆ«
        if analysis['memory_usage_ratio'] > 0.9:
            analysis['warning_level'] = 'critical'
            analysis['message'] = 'âš ï¸  å†…å­˜ä¸¥é‡ä¸è¶³ï¼Œå¼ºçƒˆå»ºè®®å‡å°‘n_jobs'
        elif analysis['memory_usage_ratio'] > 0.7:
            analysis['warning_level'] = 'warning'
            analysis['message'] = 'âš ï¸  å†…å­˜ç´§å¼ ï¼Œå»ºè®®å‡å°‘n_jobs'
        elif analysis['needs_adjustment']:
            analysis['warning_level'] = 'info'
            analysis['message'] = 'â„¹ï¸  å»ºè®®è°ƒæ•´n_jobsä»¥è·å¾—æœ€ä½³æ€§èƒ½'
        else:
            analysis['message'] = 'âœ… èµ„æºå……è¶³ï¼Œå¯ä»¥ä½¿ç”¨è¯·æ±‚çš„n_jobs'

        return analysis

    def print_memory_analysis(self, data_shape: Tuple[int, int], method: str = None) -> None:
        """
        æ‰“å°å†…å­˜åˆ†æç»“æœã€‚

        Parameters
        ----------
        data_shape : Tuple[int, int]
            æ•°æ®å½¢çŠ¶ (T, N)
        method : str, optional
            è®¡ç®—æ–¹æ³•
        """
        analysis = self.check_memory_requirements(data_shape, method)

        print("=" * 60)
        print("ğŸ§  å†…å­˜ä½¿ç”¨åˆ†æ")
        print("=" * 60)
        print(f"æ•°æ®å½¢çŠ¶: {analysis['data_shape'][0]}å¤© Ã— {analysis['data_shape'][1]}åªè‚¡ç¥¨")
        print(f"è®¡ç®—æ–¹æ³•: {analysis['method'].upper()}")
        print(f"è¯·æ±‚çš„n_jobs: {analysis['requested_n_jobs']}")
        print(f"æ¨èçš„n_jobs: {analysis['recommended_n_jobs']}")
        print(f"CPUæ ¸å¿ƒæ•°: {analysis['cpu_cores']}")
        print()
        print(f"ä¼°ç®—å†…å­˜éœ€æ±‚: {analysis['estimated_memory_gb']:.2f}GB")
        print(f"å¯ç”¨å†…å­˜: {analysis['available_memory_gb']:.2f}GB")
        print(f"å†…å­˜ä½¿ç”¨æ¯”ä¾‹: {analysis['memory_usage_ratio']:.1%}")
        print()
        print(f"çŠ¶æ€: {analysis['message']}")
        print("=" * 60)

    def _create_adjacency_matrix(
        self, lead_lag_matrix: np.ndarray, absolute_values: bool = True
    ) -> np.ndarray:
        """
        ä»é¢†å…ˆ-æ»åçŸ©é˜µåˆ›å»ºæœ‰å‘é‚»æ¥çŸ©é˜µã€‚

        é‚»æ¥çŸ©é˜µ A å®šä¹‰ä¸º:
        A[i,j] = |M[i,j]| (å¦‚æœ absolute_values=True) æˆ– M[i,j]

        Parameters
        ----------
        lead_lag_matrix : np.ndarray
            é¢†å…ˆ-æ»åç›¸å…³æ€§çŸ©é˜µã€‚
        absolute_values : bool, optional
            æ˜¯å¦å¯¹ç›¸å…³æ€§å–ç»å¯¹å€¼, by default Trueã€‚

        Returns
        -------
        np.ndarray
            æœ‰å‘é‚»æ¥çŸ©é˜µ Aã€‚
        """
        if absolute_values:
            # NumPyæ•°ç»„ä½¿ç”¨ np.abs()
            A = np.abs(lead_lag_matrix)
        else:
            A = lead_lag_matrix.copy()

        return A

    def build_network(
        self,
        network_type: str = "overnight_lead_daytime",
        absolute_values: bool = True,
        correlation_method: str = None
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ„å»ºä¸€ä¸ªå®Œæ•´çš„é¢†å…ˆ-æ»åç½‘ç»œã€‚

        Parameters
        ----------
        network_type : str, optional
            è¦æ„å»ºçš„ç½‘ç»œç±»å‹ï¼Œå¯é€‰å€¼ä¸º:
            - "overnight_lead_daytime"
            - "daytime_lead_overnight"
            by default "overnight_lead_daytime"ã€‚
        absolute_values : bool, optional
            æ˜¯å¦åœ¨æ„å»ºé‚»æ¥çŸ©é˜µæ—¶ä½¿ç”¨ç»å¯¹å€¼, by default Trueã€‚
        correlation_method : str, optional
            ç›¸å…³æ€§è®¡ç®—æ–¹æ³•ï¼Œå¯é€‰ 'pearson' æˆ– 'spearman'ã€‚
            å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨å®ä¾‹åˆå§‹åŒ–æ—¶è®¾ç½®çš„æ–¹æ³•ï¼Œby default Noneã€‚

        Returns
        -------
        Tuple[np.ndarray, np.ndarray]
            ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å« (é¢†å…ˆ-æ»åçŸ©é˜µ M, é‚»æ¥çŸ©é˜µ A)ã€‚
            ä¸¤ä¸ªçŸ©é˜µçš„å½¢çŠ¶å‡ä¸º (D, N, N)ã€‚

        Raises
        ------
        ValueError
            å½“ç½‘ç»œç±»å‹æˆ–ç›¸å…³æ€§æ–¹æ³•ä¸æ”¯æŒæ—¶ã€‚

        Notes
        -----
        å¹¶è¡Œè®¡ç®—ä½¿ç”¨å®ä¾‹åˆå§‹åŒ–æ—¶è®¾ç½®çš„n_jobså‚æ•°ã€‚
        å¯ä»¥é€šè¿‡set_n_jobs()æ–¹æ³•åŠ¨æ€è°ƒæ•´å¹¶è¡Œåº¦ã€‚
        """
        # ç¡®å®šä½¿ç”¨çš„ç›¸å…³æ€§æ–¹æ³•
        method = correlation_method if correlation_method is not None else self._correlation_method
        method = self._validate_correlation_method(method)

        # æ ¹æ®ç½‘ç»œç±»å‹æ„å»ºé¢†å…ˆ-æ»åçŸ©é˜µ
        if network_type == "overnight_lead_daytime":
            M: np.ndarray = compute_rolling_lead_lag(
                self._qlib_provider.overnight_return_df.fillna(0),
                self._qlib_provider.daytime_return_df.fillna(0),
                self._lookback_window,
                method=method,
                n_jobs=self._requested_n_jobs,
                parallel_config=self._parallel_config,
            )

        elif network_type == "daytime_lead_overnight":
            M: np.ndarray = compute_rolling_lead_lag(
                self._qlib_provider.daytime_return_df.shift(1).fillna(0),
                self._qlib_provider.overnight_return_df.fillna(0),
                self._lookback_window,
                method=method,
                n_jobs=self._requested_n_jobs,
                parallel_config=self._parallel_config,
            )

        else:
            raise ValueError(f"æœªçŸ¥çš„ç½‘ç»œç±»å‹: {network_type}. "
                           f"æ”¯æŒçš„ç±»å‹: ['overnight_lead_daytime', 'daytime_lead_overnight']")

        # åˆ›å»ºé‚»æ¥çŸ©é˜µ
        A = self._create_adjacency_matrix(M, absolute_values)

        return M, A

    def build_multiple_networks(
        self,
        network_types: List[str] = None,
        correlation_methods: List[str] = None,
        absolute_values: bool = True
    ) -> dict:
        """
        æ„å»ºå¤šç§ç±»å‹çš„ç½‘ç»œï¼Œä¾¿äºæ¯”è¾ƒåˆ†æã€‚

        Parameters
        ----------
        network_types : List[str], optional
            è¦æ„å»ºçš„ç½‘ç»œç±»å‹åˆ—è¡¨ï¼Œé»˜è®¤æ„å»ºä¸¤ç§ç±»å‹ã€‚
        correlation_methods : List[str], optional
            è¦ä½¿ç”¨çš„ç›¸å…³æ€§æ–¹æ³•åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰æ–¹æ³•ã€‚
        absolute_values : bool, optional
            æ˜¯å¦åœ¨æ„å»ºé‚»æ¥çŸ©é˜µæ—¶ä½¿ç”¨ç»å¯¹å€¼, by default Trueã€‚

        Returns
        -------
        dict
            åŒ…å«å¤šç§ç½‘ç»œç»“æœçš„å­—å…¸ï¼Œé”®ä¸º "network_type_correlation_method" æ ¼å¼ï¼Œ
            å€¼ä¸ºåŒ…å« (M, A) çš„å…ƒç»„ã€‚

        Example
        -------
        >>> builder = LeadLagNetworkBuilder(provider, correlation_method="pearson")
        >>> networks = builder.build_multiple_networks(
        ...     network_types=["overnight_lead_daytime", "daytime_lead_overnight"],
        ...     correlation_methods=["pearson", "spearman"]
        ... )
        >>> # è®¿é—®ç‰¹å®šç½‘ç»œ
        >>> M_pearson, A_pearson = networks["overnight_lead_daytime_pearson"]
        """
        # è®¾ç½®é»˜è®¤å€¼
        if network_types is None:
            network_types = ["overnight_lead_daytime", "daytime_lead_overnight"]

        if correlation_methods is None:
            correlation_methods = [self._correlation_method]

        results = {}

        for network_type in network_types:
            for method in correlation_methods:
                key = f"{network_type}_{method}"
                try:
                    M, A = self.build_network(
                        network_type=network_type,
                        absolute_values=absolute_values,
                        correlation_method=method
                    )
                    results[key] = {"M": M, "A": A}
                except Exception as e:
                    print(f"æ„å»ºç½‘ç»œ {key} æ—¶å‡ºé”™: {e}")
                    continue

        return results



